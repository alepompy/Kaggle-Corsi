{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fddb4a9d",
   "metadata": {},
   "source": [
    "### Random Forests\n",
    "Gli alberi decisionali lasciano una decisione difficile. Un albero profondo con molte foglie si adatterà in modo eccessivo perché ogni previsione proviene dai dati storici delle poche case che si trovano alla sua estremità. Ma un albero poco profondo con poche foglie avrà un rendimento scarso perché non riesce a cogliere altrettante distinzioni nei dati grezzi.\n",
    "\n",
    "Anche le tecniche di modellazione più sofisticate di oggi devono affrontare questa tensione tra underfitting e overfitting. Tuttavia, molti modelli hanno idee intelligenti che possono portare a prestazioni migliori. Un esempio è la foresta casuale.\n",
    "\n",
    "La foresta casuale utilizza molti alberi e fa una previsione calcolando la media delle previsioni di ciascun albero componente. In genere ha un'accuratezza predittiva molto migliore di un singolo albero decisionale e funziona bene con parametri predefiniti. Se si continua a modellare, si possono imparare altri modelli con prestazioni ancora migliori, ma molti di questi sono sensibili alla scelta dei parametri giusti."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bf5510",
   "metadata": {},
   "source": [
    "### Esempio\n",
    "Esempio\n",
    "Il codice per caricare i dati è già stato visto alcune volte. Al termine del caricamento dei dati, abbiamo le seguenti variabili **train_X**, **val_X***, **train_y** e **val_y**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f278505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "    \n",
    "# Load data\n",
    "melbourne_file_path = 'D:/Users/Alessio/OneDrive/Python/Kaggle/Intro to Machine Learning/melb_data.csv'\n",
    "melbourne_data = pd.read_csv(melbourne_file_path) \n",
    "# Filter rows with missing values\n",
    "melbourne_data = melbourne_data.dropna(axis=0)\n",
    "# Choose target and features\n",
    "y = melbourne_data.Price\n",
    "melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'BuildingArea', \n",
    "                        'YearBuilt', 'Lattitude', 'Longtitude']\n",
    "X = melbourne_data[melbourne_features]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data into training and validation data, for both features and target\n",
    "# The split is based on a random number generator. Supplying a numeric value to\n",
    "# the random_state argument guarantees we get the same split every time we\n",
    "# run this script.\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y,random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acb8add",
   "metadata": {},
   "source": [
    "Costruiamo un modello di foresta casuale in modo simile a come abbiamo costruito un albero decisionale in **scikit-learn**, questa volta usando la classe **RandomForestRegressor** invece di _DecisionTreeRegressor_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaca043f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191669.7536453626\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "forest_model = RandomForestRegressor(random_state=1)\n",
    "forest_model.fit(train_X, train_y)\n",
    "melb_preds = forest_model.predict(val_X)\n",
    "print(mean_absolute_error(val_y, melb_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a3360b",
   "metadata": {},
   "source": [
    "È probabile che ci sia spazio per ulteriori miglioramenti, ma si tratta di un grande miglioramento rispetto al miglior errore dell'albero decisionale, pari a 250.000. Esistono parametri che consentono di modificare le prestazioni della Foresta casuale, così come abbiamo modificato la profondità massima del singolo albero decisionale. Ma una delle caratteristiche migliori dei modelli Random Forest è che in genere funzionano discretamente anche senza questa regolazione."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef89d94",
   "metadata": {},
   "source": [
    "## Esercizi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0828dd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAE when not specifying max_leaf_nodes: 29,653\n",
      "Validation MAE for best value of max_leaf_nodes: 27,283\n"
     ]
    }
   ],
   "source": [
    "# Code you have previously used to load data\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "# Path of the file to read\n",
    "iowa_file_path = 'D:/Users/Alessio/OneDrive/Python/Kaggle/Intro to Machine Learning/train.csv'\n",
    "\n",
    "home_data = pd.read_csv(iowa_file_path)\n",
    "# Create target object and call it y\n",
    "y = home_data.SalePrice\n",
    "# Create X\n",
    "features = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
    "X = home_data[features]\n",
    "\n",
    "# Split into validation and training data\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# Specify Model\n",
    "iowa_model = DecisionTreeRegressor(random_state=1)\n",
    "# Fit Model\n",
    "iowa_model.fit(train_X, train_y)\n",
    "\n",
    "# Make validation predictions and calculate mean absolute error\n",
    "val_predictions = iowa_model.predict(val_X)\n",
    "val_mae = mean_absolute_error(val_predictions, val_y)\n",
    "print(\"Validation MAE when not specifying max_leaf_nodes: {:,.0f}\".format(val_mae))\n",
    "\n",
    "# Using best value for max_leaf_nodes\n",
    "iowa_model = DecisionTreeRegressor(max_leaf_nodes=100, random_state=1)\n",
    "iowa_model.fit(train_X, train_y)\n",
    "val_predictions = iowa_model.predict(val_X)\n",
    "val_mae = mean_absolute_error(val_predictions, val_y)\n",
    "print(\"Validation MAE for best value of max_leaf_nodes: {:,.0f}\".format(val_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a619a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setup complete\n"
     ]
    }
   ],
   "source": [
    "# Set up code checking\n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.machine_learning.ex6 import *\n",
    "print(\"\\nSetup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966aee73",
   "metadata": {},
   "source": [
    "### Domanda 1\n",
    "Usare un Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71dc6528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAE for Random Forest Model: 22253.04619830398\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 1.0, \"interactionType\": 1, \"questionType\": 2, \"questionId\": \"1_CheckRfScore\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc33\">Correct</span>"
      ],
      "text/plain": [
       "Correct"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Define the model. Set random_state to 1\n",
    "rf_model = RandomForestRegressor()\n",
    "\n",
    "# fit your model\n",
    "rf_model.fit(train_X, train_y)\n",
    "\n",
    "# Calculate the mean absolute error of your Random Forest model on the validation data\n",
    "rf_val_predictions = rf_model.predict(val_X)\n",
    "rf_val_mae = mean_absolute_error(rf_val_predictions, val_y)\n",
    "\n",
    "print(\"Validation MAE for Random Forest Model: {}\".format(rf_val_mae))\n",
    "\n",
    "# Check your answer\n",
    "step_1.check()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
